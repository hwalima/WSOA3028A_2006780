<!DOCTYPE html>
<html lang="en">

<head>
    <meta property="og:title" content="James Dladla" />
    <meta property="og:type" content="Website" />
    <meta property="og:url" content="https://hwalima.github.io/WSOA3028A_2006780/" />
    <meta property="og:image" content="./images/Sikhue Chibby 5.png" />
    <meta name="description" content="James Dladla's website about his life as a Johannesburg photographer.">
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Blog 10</title>
    <!--for menu-->
    <script src="../javaScript/navMenu.js"></script>
    <link rel="stylesheet" href="../CSS/mainmenu.css">
    <!--favicon-->
    <!--blogs-->
    <link rel="stylesheet" href="../CSS/blog.css">
    <!--Icons-->
    <link rel="stylesheet" href="https://pro.fontawesome.com/releases/v5.14.0/css/all.css">
    <!--favicon-->
    <link rel="shortcut icon" type="image/mng" href="../images/Sikhue Chibby 5.png" alt="Chibby" />

    <!--footer-->
    <script src="footer.js"></script>
    <link rel="stylesheet" href="../CSS/footer.css">
</head>

<body>
    <!-- navigation starts here-->

    <!-- navigation ends here-->
    <!-- content starts here-->
    <section class="top">
        <section class="header">
            <h1><strong>An AI called FAMA.</strong></h1>
            <h2 class="author">Digitally identifies problematic behavior. 530 words.</h2>

        </section>
    </section>
    <section class="content">
        <section class="date">
            <strong>June</strong>
            <strong class="day">14</strong>
        </section>
        <section class="article">
            <h2>Introduction</h2>
            <p class="firstpara"><strong class="firstcharacter">T</strong>he rapid advancement of the digital economy
                has led to the emergence of an extensive array of new and innovative technological methodologies to
                assist with personnel selection decisions (McCarthy et al., 2017; Nikolaou, 2014).</p>

        </section>
        <section class="date">
            <strong>June</strong>
            <strong class="day">14</strong>
        </section>
        <section class="article">
            <h2>Your digital footprint.</h2>

            <img src="../images/fama.jpg" alt="Fama" />
            <p class="firstpara"><strong class="firstcharacter">N</strong>amed from a Latin term translated to “Fame
                via reputation”. Fama Technologies uses artificial intelligence to help weed out problematic employees
                before they are even hired by an organization. According to Fama.io website, the tech company claims
                that the algorithm powered software smartly screen out problematic workplace behavior in potential
                employees and helps ease the work for tradition human resources departments. The software basically
                sniffs through a potential employee’s digital footprint, especially publicly available data like social
                media. </p>
            <section class="pause" id="i"><a href="#i">According to their website:</a></section>
            <p>“Fama provides an automated solution that identifies problematic behavior among potential hires and
                current employees by analysing publicly available online information. Enterprise HR and Talent leaders
                trust Fama to help identify behaviors such as bigotry and harassment that are often missed in the hiring
                process. With Fama, organizations can now improve workplace culture and protect their employees from
                harassment and toxic behaviors before they escalate to more serious concerns and expose the brand to
                liability.” From <a href="http://www.fama.io" target="_blank">http://www.fama.io</a></p> <br>

            <iframe width="560" height="315" src="https://www.youtube.com/embed/-6Pc643rB60"
                title="YouTube video player" frameborder="0"
                allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                allowfullscreen></iframe>


            <section class="pause" id="ii"><a href="#ii">My thoughts.</a></section>
            <p>Notwithstanding the fact that every organization should prioritize and cultivate a comfortable and safe
                working environment for all their employees, what is the ultimate cost that a company pays for such an
                activity? More so, what is the cost for the potential employee. There are serious implications to
                privacy at play here. Investing in algorithm powered AI ttargets people based on their digital
                footprint, not on their humanity.</p>
        </section>
        <section class="date">
            <strong>June</strong>
            <strong class="day">14</strong>
        </section>
        <section class="article">
            <h2>Scholarly debates.</h2>
            <img src="../images/recruiting.jpg" alt="Digital recruiting" />
            <p>As much as Technologies like Fama help cast the net wider that where a human being could possibly reach,
                there are still limitation. Scholars like Le Corff, Gingras, and Busque‐Carrier (2017) argue that
                methodological limitations of equivalence studies may bias results.</p>
        </section>
        <section class="article">
            <h2>The argument.</h2>
            <iframe width="560" height="315" src="https://www.youtube.com/embed/8QEK7B9GUhM"
                title="YouTube video player" frameborder="0"
                allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                allowfullscreen></iframe>
            <p>I believe measuring a human being using yesterday’s yardsticks is retrogressive. People evolve, people
                are dynamic creations. My statements in Facebook five years ago do not and must not be a mirror image of
                what I ma, or might say today.</p>
            <p>While this would seem like a simple and desirable solution at first you must wonder what the AI’s guild
                lines are based off. What are the traits that they are looking for that give employees the red light? We
                hope that the algorithms and designs used by Fama are unbiased and in the right way for finding
                undesirable employees. Hopefully, employees with a red light do have an opportunity to redeem or explain
                themselves from what they might done or posted in their past online and not be able to ever apply again.
            </p>
        </section>
        <section class="article">
            <h2>Digital footprints</h2>

            <img src="../images/digitalFootprint.jpg" alt="digital footprint" />
            <p class="firstpara"><strong class="firstcharacter">F</strong>"ama analyzes a candidate or current
                employee’s digital footprint through their publicly available online data, with the goal of identifying
                any potential risks posed to the organization, which could include bigotry, sexism, and harassment."
                (Onesto 2020)</p>
            <section class="pause" id="i"><a href="#i">CareerBuilder.</a></section>
            <p>According to CareerBuilder, 60% of organizations are using public social media or online searching to
                screen job applicants in 2016. However, most of those companies do it manually.” Some companies wish to
                remove the liability from their Human Resources (HR) department by using Fama instead of asking the HR
                employees to perform manual Social Media background checks.</p> <br>

        </section>

        <section class="date">
            <strong>June</strong>
            <strong class="day">14</strong>
        </section>
        <section class="article">
            <h2>Bibliography</h2>

            <p>Onesto, L. Hireright Introduces Social Media Screening Through Partnership With Fama Technologies.
                [online] Businesswire.com. Available at:
                https://www.businesswire.com/news/home/20200331005095/en/HireRight-Introduces-Social-Media-Screening-Partnership-Fama
                [Accessed 14 June 2021].</p>
            <br>
            <p>
                DeMuro, R., 2020. Companies Are Using Artificial Intelligence To Screen For Problematic Employees.
                [online] KTLA5. Available at:
                https://ktla.com/morning-news/technology/fama-social-media-screening-machine-learning-job-applicant-risk/
                [Accessed 14 June 2021].
            </p>
            <br>
            <p>
                Nikolaou, I., 2021. What is the Role of Technology in Recruitment and Selection?. The Spanish Journal of
                Psychology, 24.
            </p>
        </section>
    </section>

    <section class="prev"><a href="blog9.html">Prev</a></section>
    <section class="next"><a href="blog11.html">Next</a></section>




    <!-- footer starts here-->
    <my-footer></my-footer>
    <!-- footer ends here-->

</body>

</html>